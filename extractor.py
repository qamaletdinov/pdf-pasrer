import json
import logging
from typing import Optional, Dict, Any
from pathlib import Path
from dataclasses import dataclass, asdict
from abc import ABC, abstractmethod

# PDF –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
try:
    import PyPDF2
except ImportError:
    PyPDF2 = None

try:
    import pdfplumber
except ImportError:
    pdfplumber = None

try:
    from pdfminer.high_level import extract_text
except ImportError:
    extract_text = None


@dataclass
class ExtractionResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞"""
    file_path: str
    method_used: str
    text: str
    text_length: int
    lines_count: int
    words_count: int
    extraction_quality_score: float
    error_message: Optional[str] = None


class PDFTextExtractor(ABC):
    """–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞"""

    @abstractmethod
    def extract(self, pdf_path: Path) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF —Ñ–∞–π–ª–∞"""
        pass

    @abstractmethod
    def get_method_name(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è"""
        pass


class PyPDF2Extractor(PDFTextExtractor):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é PyPDF2"""

    def extract(self, pdf_path: Path) -> str:
        if PyPDF2 is None:
            raise ImportError("PyPDF2 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

        text = ""
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            for page_num, page in enumerate(reader.pages):
                try:
                    page_text = page.extract_text()
                    if page_text:
                        text += f"\n=== –°–¢–†–ê–ù–ò–¶–ê {page_num + 1} ===\n"
                        text += page_text + "\n"
                except Exception as e:
                    logging.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num + 1}: {e}")

        return text

    def get_method_name(self) -> str:
        return "PyPDF2"


class PdfPlumberExtractor(PDFTextExtractor):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é pdfplumber"""

    def extract(self, pdf_path: Path) -> str:
        if pdfplumber is None:
            raise ImportError("pdfplumber –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

        text = ""
        with pdfplumber.open(pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages):
                try:
                    page_text = page.extract_text()
                    if page_text:
                        text += f"\n=== –°–¢–†–ê–ù–ò–¶–ê {page_num + 1} ===\n"
                        text += page_text + "\n"

                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã –µ—Å–ª–∏ –µ—Å—Ç—å
                    tables = page.extract_tables()
                    if tables:
                        text += f"\n--- –¢–ê–ë–õ–ò–¶–´ –ù–ê –°–¢–†–ê–ù–ò–¶–ï {page_num + 1} ---\n"
                        for table_num, table in enumerate(tables):
                            text += f"–¢–∞–±–ª–∏—Ü–∞ {table_num + 1}:\n"
                            for row in table:
                                if row:
                                    text += " | ".join(str(cell) if cell else "" for cell in row) + "\n"
                            text += "\n"

                except Exception as e:
                    logging.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num + 1}: {e}")

        return text

    def get_method_name(self) -> str:
        return "pdfplumber"


class PdfMinerExtractor(PDFTextExtractor):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é pdfminer"""

    def extract(self, pdf_path: Path) -> str:
        if extract_text is None:
            raise ImportError("pdfminer –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

        return extract_text(str(pdf_path))

    def get_method_name(self) -> str:
        return "pdfminer"


class TextQualityAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""

    @staticmethod
    def analyze_quality(text: str) -> float:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –æ—Ç 0 –¥–æ 1"""
        if not text:
            return 0.0

        # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        scores = []

        # 1. –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ (–±–æ–ª—å—à–µ = –ª—É—á—à–µ, –¥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥–µ–ª–∞)
        length_score = min(len(text) / 5000, 1.0)
        scores.append(length_score * 0.2)

        # 2. –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —á–∏—Ç–∞–µ–º—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        total_chars = len(text)
        readable_chars = len([c for c in text if c.isalnum() or c.isspace() or c in '.,!?;:()[]{}'])
        readable_ratio = readable_chars / total_chars if total_chars > 0 else 0
        scores.append(readable_ratio * 0.3)

        # 3. –ù–∞–ª–∏—á–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫)
        lines = text.count('\n')
        structure_score = min(lines / 100, 1.0)
        scores.append(structure_score * 0.2)

        # 4. –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Å–ª–æ–≤
        words = text.split()
        unique_words = len(set(word.lower() for word in words))
        diversity_score = min(unique_words / len(words), 1.0) if words else 0
        scores.append(diversity_score * 0.15)

        # 5. –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —Å–∏–º–≤–æ–ª–æ–≤ (–ø—Ä–∏–∑–Ω–∞–∫ –ø–ª–æ—Ö–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è)
        repeated_chars = sum(1 for i in range(len(text) - 2)
                             if text[i] == text[i + 1] == text[i + 2])
        no_repetition_score = max(0, 1 - (repeated_chars / len(text)))
        scores.append(no_repetition_score * 0.15)

        return sum(scores)


class AdvancedPDFExtractor:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∏–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å —Ç–µ–∫—Å—Ç–∞ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏"""

    def __init__(self):
        self.extractors = []
        self.quality_analyzer = TextQualityAnalyzer()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω—ã—Ö extractors
        if pdfplumber:
            self.extractors.append(PdfPlumberExtractor())
        if PyPDF2:
            self.extractors.append(PyPDF2Extractor())
        if extract_text:
            self.extractors.append(PdfMinerExtractor())

        if not self.extractors:
            raise ImportError(
                "–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –Ω–∏ –æ–¥–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å PDF. "
                "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install PyPDF2 pdfplumber pdfminer.six"
            )

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('pdf_extraction.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def extract_with_all_methods(self, pdf_path: str) -> Dict[str, ExtractionResult]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –≤—Å–µ–º–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        path = Path(pdf_path)

        if not path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª {pdf_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")

        results = {}

        for extractor in self.extractors:
            method_name = extractor.get_method_name()
            self.logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –º–µ—Ç–æ–¥–æ–º: {method_name}")

            try:
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
                text = extractor.extract(path)

                # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞
                quality_score = self.quality_analyzer.analyze_quality(text)

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                lines_count = text.count('\n')
                words_count = len(text.split())

                result = ExtractionResult(
                    file_path=str(path),
                    method_used=method_name,
                    text=text,
                    text_length=len(text),
                    lines_count=lines_count,
                    words_count=words_count,
                    extraction_quality_score=quality_score
                )

                results[method_name] = result

                self.logger.info(
                    f"{method_name}: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤, "
                    f"–∫–∞—á–µ—Å—Ç–≤–æ: {quality_score:.3f}"
                )

            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ {method_name}: {str(e)}"
                self.logger.error(error_msg)

                result = ExtractionResult(
                    file_path=str(path),
                    method_used=method_name,
                    text="",
                    text_length=0,
                    lines_count=0,
                    words_count=0,
                    extraction_quality_score=0.0,
                    error_message=error_msg
                )

                results[method_name] = result

        return results

    def extract_best_text(self, pdf_path: str) -> ExtractionResult:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –ª—É—á—à–∏–º –¥–æ—Å—Ç—É–ø–Ω—ã–º –º–µ—Ç–æ–¥–æ–º"""
        results = self.extract_with_all_methods(pdf_path)

        # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        best_result = max(
            results.values(),
            key=lambda r: r.extraction_quality_score
        )

        self.logger.info(
            f"–õ—É—á—à–∏–π –º–µ—Ç–æ–¥: {best_result.method_used} "
            f"(–∫–∞—á–µ—Å—Ç–≤–æ: {best_result.extraction_quality_score:.3f})"
        )

        return best_result

    def save_extraction_results(self, pdf_path: str, output_dir: str = "extraction_results"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤—Å–µ–º–∏ –º–µ—Ç–æ–¥–∞–º–∏"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        pdf_name = Path(pdf_path).stem
        results = self.extract_with_all_methods(pdf_path)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∫–∞–∂–¥—ã–º –º–µ—Ç–æ–¥–æ–º
        for method_name, result in results.items():
            if result.text:
                text_file = output_path / f"{pdf_name}_{method_name}.txt"
                with open(text_file, 'w', encoding='utf-8') as f:
                    f.write(f"=== –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –ú–ï–¢–û–î–û–ú: {method_name} ===\n")
                    f.write(f"–§–∞–π–ª: {result.file_path}\n")
                    f.write(f"–î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {result.text_length} —Å–∏–º–≤–æ–ª–æ–≤\n")
                    f.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {result.lines_count}\n")
                    f.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤: {result.words_count}\n")
                    f.write(f"–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {result.extraction_quality_score:.3f}\n")
                    f.write("=" * 50 + "\n\n")
                    f.write(result.text)

                self.logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω: {text_file}")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        report_file = output_path / f"{pdf_name}_comparison_report.json"
        report_data = {
            "file_path": pdf_path,
            "extraction_timestamp": "2025-09-01 18:51:34",
            "methods_comparison": {}
        }

        for method_name, result in results.items():
            report_data["methods_comparison"][method_name] = {
                "success": result.error_message is None,
                "text_length": result.text_length,
                "lines_count": result.lines_count,
                "words_count": result.words_count,
                "quality_score": result.extraction_quality_score,
                "error_message": result.error_message
            }

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –º–µ—Ç–æ–¥
        best_method = max(
            results.keys(),
            key=lambda k: results[k].extraction_quality_score
        )
        report_data["recommended_method"] = best_method

        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)

        self.logger.info(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")

        return report_data

    def analyze_text_structure(self, text: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        lines = text.split('\n')

        analysis = {
            "–æ–±—â–∞—è_—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞": {
                "–≤—Å–µ–≥–æ_—Å–∏–º–≤–æ–ª–æ–≤": len(text),
                "–≤—Å–µ–≥–æ_—Å—Ç—Ä–æ–∫": len(lines),
                "–≤—Å–µ–≥–æ_—Å–ª–æ–≤": len(text.split()),
                "–ø—É—Å—Ç—ã—Ö_—Å—Ç—Ä–æ–∫": sum(1 for line in lines if not line.strip())
            },
            "—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ_—ç–ª–µ–º–µ–Ω—Ç—ã": {
                "–∑–∞–≥–æ–ª–æ–≤–∫–∏": [],
                "—Å–µ–∫—Ü–∏–∏": [],
                "–∫–æ–Ω—Ç–∞–∫—Ç–Ω–∞—è_–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è": {},
                "–¥–∞—Ç—ã": [],
                "email_–∞–¥—Ä–µ—Å–∞": [],
                "—Ç–µ–ª–µ—Ñ–æ–Ω—ã": []
            }
        }

        # –ü–æ–∏—Å–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (–∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ –≤ –≤–µ—Ä—Ö–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ)
        for i, line in enumerate(lines[:20]):
            line = line.strip()
            if line and len(line) < 50 and (line.isupper() or line.istitle()):
                analysis["—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ_—ç–ª–µ–º–µ–Ω—Ç—ã"]["–∑–∞–≥–æ–ª–æ–≤–∫–∏"].append({
                    "—Å—Ç—Ä–æ–∫–∞": i + 1,
                    "—Ç–µ–∫—Å—Ç": line
                })

        # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–∞–∫—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        import re

        email_pattern = re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b')
        phone_pattern = re.compile(r'(\+?7[\s\-\(\)]?\d{3}[\s\-\(\)]?\d{3}[\s\-]?\d{2}[\s\-]?\d{2})')
        date_pattern = re.compile(r'\b\d{1,2}[\.\/\-]\d{1,2}[\.\/\-]\d{2,4}\b|\b\d{4}\b')

        analysis["—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ_—ç–ª–µ–º–µ–Ω—Ç—ã"]["email_–∞–¥—Ä–µ—Å–∞"] = email_pattern.findall(text)
        analysis["—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ_—ç–ª–µ–º–µ–Ω—Ç—ã"]["—Ç–µ–ª–µ—Ñ–æ–Ω—ã"] = phone_pattern.findall(text)
        analysis["—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ_—ç–ª–µ–º–µ–Ω—Ç—ã"]["–¥–∞—Ç—ã"] = date_pattern.findall(text)

        return analysis


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã"""
    extractor = AdvancedPDFExtractor()

    print("üîç PDF Text Extractor v1.0")
    print("=" * 50)
    print("–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:")

    for i, ext in enumerate(extractor.extractors, 1):
        print(f"  {i}. {ext.get_method_name()}")

    print("\n" + "=" * 50)

    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    pdf_file = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É: ").strip()

    if not pdf_file:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        print("–î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª 'test_resume.pdf' –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É PDF")
        return

    try:
        print(f"\nüìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {pdf_file}")

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
        print("üîÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤—Å–µ–º–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏...")
        report = extractor.save_extraction_results(pdf_file)

        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:")
        for method, stats in report["methods_comparison"].items():
            if stats["success"]:
                print(f"  ‚úÖ {method}: {stats['text_length']} —Å–∏–º–≤–æ–ª–æ–≤, "
                      f"–∫–∞—á–µ—Å—Ç–≤–æ: {stats['quality_score']:.3f}")
            else:
                print(f"  ‚ùå {method}: {stats['error_message']}")

        print(f"\nüèÜ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –º–µ—Ç–æ–¥: {report['recommended_method']}")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        best_result = extractor.extract_best_text(pdf_file)

        if best_result.text:
            # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            print("\nüîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–µ–∫—Å—Ç–∞...")
            structure = extractor.analyze_text_structure(best_result.text)

            print(f"üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
            stats = structure["–æ–±—â–∞—è_—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"]
            print(f"  ‚Ä¢ –°–∏–º–≤–æ–ª–æ–≤: {stats['–≤—Å–µ–≥–æ_—Å–∏–º–≤–æ–ª–æ–≤']}")
            print(f"  ‚Ä¢ –°—Ç—Ä–æ–∫: {stats['–≤—Å–µ–≥–æ_—Å—Ç—Ä–æ–∫']}")
            print(f"  ‚Ä¢ –°–ª–æ–≤: {stats['–≤—Å–µ–≥–æ_—Å–ª–æ–≤']}")

            elements = structure["—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ_—ç–ª–µ–º–µ–Ω—Ç—ã"]
            if elements["email_–∞–¥—Ä–µ—Å–∞"]:
                print(f"  ‚Ä¢ Email: {', '.join(elements['email_–∞–¥—Ä–µ—Å–∞'])}")
            if elements["—Ç–µ–ª–µ—Ñ–æ–Ω—ã"]:
                print(f"  ‚Ä¢ –¢–µ–ª–µ—Ñ–æ–Ω—ã: {', '.join(elements['—Ç–µ–ª–µ—Ñ–æ–Ω—ã'])}")

            print(f"\nüíæ –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫—É 'extraction_results/'")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
            print(f"\nüìñ –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤):")
            print("-" * 50)
            print(best_result.text[:500])
            if len(best_result.text) > 500:
                print("...")
            print("-" * 50)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()